\chapter{Conclusion générale}
Dans ce mémoire nous avons étudié le paradigme du Fog Computing qui évolue rapidement pour atténuer les problèmes de latence, de bande passante et de qualité de service (QoS) des applications basées sur le cloud. Nous avons présenté les efforts de recherches axés sur l'optimisation de l'exploitation des ressources que propose cette architecture.\par
A notre tour, nous avons proposé un algorithme décentralisé pour la distribution équitable des demandes de services par lot sur l'ensemble de nœuds Fog organisés en clusters. Notre solution favorise la réactivité et la réduction du temps de réponse aux demandes, qui est un facteur critique pour les applications à temps réel qui expriment de grandes exigences de qualité de service. De plus, cette solution garantit la distribution équitable de charges de travail entre les nœuds d'un même cluster, ce qui permet d'éviter la saturation du réseau et la création de points critiques.\par
La solution présentée traite seulement le problème d'allocation de ressources, et peut être enrichie en explorant d'autres aspects de l'architecture Fog. Nous pouvons énumérer les perspectives suivantes permettant notamment d'éliminer les hypothèses formulées dans le chapitre de conception :
\begin{itemize}
  \item L'intégration d'un mécanisme de découverte du réseau permettant la construction d'une topologie logique de ce dernier. Ceci nous permettra de considérer le coût de la liaison réseau dans la fonction de distance entre les demandes et les nœuds proposée dans le chapitre de conception.
  \item Permettre l'ajout et le retrait dynamique de nœuds du cluster à l'aide d'une solution d'abonnement aux nœuds passerelles.
  \item Intégrer la notion de priorité entre les différentes demandes émanant des objets IoT. 
\end{itemize}